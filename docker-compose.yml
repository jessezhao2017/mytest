version: "2"

services:
  hbase:
    build: ./hbase
    container_name: hbase
    volumes:
      - "/tmp/hbase-data:/data-volume"
    ports:
      - 12181:2181
      - 60000:60000
      - 60010:60010
      - 60020:60020
      - 60030:60030 
    networks:
      - back-tier

  redis:
    image: redis:alpine
    container_name: redis
    ports: 
      - 16379:6379
    networks:
      - back-tier

  postgres:
    image: sameersbn/postgresql:9.6-2
    container_name: postgres
    environment:
      - DEBUG=false
      - DB_USER=airflow 
      - DB_PASS=airflow
      - DB_NAME=airflow,mytest
    ports:
      - 15432:5432
    volumes:
      - "postgres-data:/var/lib/postgresql/data"
    networks:
      - back-tier

  airflow:
    image: puckel/docker-airflow:1.8.1
    container_name: airflow
    restart: always
    depends_on:
      - postgres
    environment:
      - LOAD_EX=y
      - EXECUTOR=Local
    volumes:
      - ./airflow/dags:/usr/local/airflow/dags
    ports:
      - "18080:8080"
    command: webserver 
    networks:
      - back-tier
 
  es:
    image: sebp/elk
    container_name: es
    environment:
      - "CLUSTER_NAME=docker-cluster"
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    mem_limit: 1g
    volumes:
      - es-data:/var/lib/elasticsearch
    ports:
      - 19200:9200
      - 15601:5601
      - 15044:5044
    networks:
      - back-tier

  spark-master:
    image: gettyimages/spark
    command: "bin/spark-class org.apache.spark.deploy.master.Master -h spark-master"
    container_name: spark-master
    environment:
       - "MASTER=spark://spark-master:7077"
       - SPARK_CONF_DIR=/conf
       - SPARK_PUBLIC_DNS=localhost
    expose:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 6066   
    ports:
      - 14040:4040
      - 16066:6066
      - 17077:7077
      - 18090:8080
    volumes:
      - ./spark/conf/master:/conf
      - ./spark/data:/tmp/data
    networks:
       - back-tier 

  spark-worker:
    image: gettyimages/spark
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    container_name: spark-worker
    environment:
      - SPARK_CONF_DIR=/conf
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_PORT=8881
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_PUBLIC_DNS=localhost
    depends_on:
      - spark-master
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 18091:8081
    volumes:
      - ./spark/conf/worker:/conf
      - ./spark/data:/tmp/data
    networks:
      - back-tier  

  zookeeper:
    image: 47deg/zookeeper
    container_name: zookeeper
    ports:
      - 2181:2181
    networks:
      - back-tier

  kafka:
    image: 47deg/kafka
    container_name: kafka
    ports:
      - 9092
    links:
      - zookeeper:zk
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - back-tier

  opscenter:
    image: 47deg/opscenter
    container_name: opscenter
    ports:
      - 18888:8888
    networks:
      - back-tier  

  cassandra_seed:
    image: 47deg/cassandra
    ports:
      - 19042:9042
    links:
      - opscenter
    container_name: cassandra_seed
    environment:
      - OPS_IP=opscenter
    networks:
      - back-tier

  cassandra_slave:
    image: 47deg/cassandra
    container_name: cassandra_slave
    links:
      - opscenter
      - cassandra_seed
    environment:
      - OPS_IP=opscenter
      - SEED=cassandra_seed
    networks:
      - back-tier

volumes:
  es-data:
    driver: local
  postgres-data:

networks:
  back-tier: